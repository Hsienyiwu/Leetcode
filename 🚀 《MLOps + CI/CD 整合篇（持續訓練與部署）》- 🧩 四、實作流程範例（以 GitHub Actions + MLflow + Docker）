Step 1ï¸âƒ£ï¼šCI â€” è‡ªå‹•è¨“ç·´èˆ‡æ¸¬è©¦

å»ºç«‹ .github/workflows/train.ymlï¼š

name: Train and Log Model

on:
  push:
    branches: [ "main" ]

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    - name: Install dependencies
      run: pip install -r requirements.txt
    - name: Train model and log to MLflow
      run: python train.py

âœ… æ¯æ¬¡æäº¤ç¨‹å¼ç¢¼å³æœƒè‡ªå‹•é‡æ–°è¨“ç·´ã€ç´€éŒ„æ¨¡å‹ã€‚

Step 2ï¸âƒ£ï¼šCD â€” è‡ªå‹•éƒ¨ç½²

æ¥çºŒ .github/workflows/deploy.ymlï¼š
name: Deploy Model via Docker

on:
  workflow_run:
    workflows: ["Train and Log Model"]
    types:
      - completed

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Build Docker image
      run: docker build -t iris-mlflow:${{ github.sha }} .
    - name: Push to Docker Hub
      run: |
        echo "${{ secrets.DOCKERHUB_TOKEN }}" | docker login -u ${{ secrets.DOCKERHUB_USER }} --password-stdin
        docker push iris-mlflow:${{ github.sha }}
ğŸ”¸ ç•¶æ¨¡å‹è¨“ç·´å®Œæˆå¾Œï¼Œè‡ªå‹•æ‰“åŒ…æ–°å®¹å™¨ä¸¦ä¸Šå‚³ã€‚

Step 3ï¸âƒ£ï¼šCT â€” è‡ªå‹•å†è¨“ç·´æ’ç¨‹

ä½¿ç”¨ Airflow æˆ– Prefect é€±æœŸæ€§åŸ·è¡Œ retrainï¼š
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import retrain_pipeline

with DAG("retrain_ml_model",
         start_date=datetime(2025,10,1),
         schedule_interval="@weekly",
         catchup=False) as dag:
    retrain = PythonOperator(
        task_id="retrain_model",
        python_callable=retrain_pipeline.run
    )
âœ… å®šæœŸåµæ¸¬è³‡æ–™æ¼‚ç§»å¾Œï¼Œè‡ªå‹•è§¸ç™¼ retrain + re-deployã€‚
